# Job 리소스

`Job` 리소스는 `Pod`와는 다르게 항상 실행되고 있는 daemon성 프로세스가 아닌 한번 실행하고 완료가 되는 batch성 프로세스를 처리하는 용도로 만들어졌습니다. 다음 `Job` 리소스에 대해서 살펴 봅시다.

```yaml
# job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: myfirstjob
spec:
  backoffLimit: 2
  activeDeadlineSeconds: 100
  template:
    spec:
      containers:
      - name: ml
        image: perl
        args: ["perl",  "-Mbignum=bpi", "-wle", "print bpi(2000)"]
      restartPolicy: OnFailure
```

- `backoffLimit`: restart 횟수를 지정합니다. 예시에서는 총 2번의 restart 시도 후 최종적으로 실패라고 기록이 됩니다.
- `activeDeadlineSeconds`: 실행하는 작업의 최대 timeout을 나타냅니다. `activeDeadlineSeconds` 시간 이후에 실패로 강제 종료됩니다.
- `template`: `Pod` 리소스의 spec과 동일합니다. `Job`도 결국은 내부적으로 `Pod`를 통해 실행되기 때문입니다.
- `restartPolicy`: 실패 시, 재시작 정책을 설정합니다.
    - `Never`: 재시작하지 않습니다.
    - `OnFailure`: 실패 시에만 재시작합니다. (`Failed`)
    - `Always`: 실패 시뿐만 아니라 종료 시에도 재시작합니다. (`Failed`, `Finished` - 주로 서비스에서 사용)


`Job`을 실행하고 어떻게 돌고 있는지 확인해 봅시다.

```bash
kubectl apply -f job.yaml

# Job 확인
kubectl get job
# NAME            COMPLETIONS   DURATION   AGE
# myfirstjob      0/1           9s         9s

# Pod 확인
kubectl get pod
# NAME                 READY   STATUS      RESTARTS   AGE
# myfirstjob-l5thh     1/1     Running     0          9s
```

여기서 확인할 수 있듯이 `Job` 리소스도 실제로는 `Pod`를 통해 컨테이너가 실행되는 것을 확인할 수 있습니다. `Pod`가 쿠버네티스의 가장 기본적인 실행단위이기 때문입니다.

이제 `Pod`의 이름을 확인하고 로그를 확인해 봅시다.

```bash
# 학습 log 확인
kubectl logs -f myfirstjob-xxx
# 3.1415926535897932384626433....
```

## ML Job 만들기

### 기본 `Job`

앞에서 만든 `my-ml-job`을 쿠버네티스 `Job`으로 제작해 봅시다. `$USERNAME/my-ml-job`은 꼭 본인의 이미지로 변경해주세요.

```yaml
# my-ml-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: my-ml-job
spec:
  template:
    spec:
      containers:
      - name: ml
        image: $USERNAME/my-ml-job
        args: ['5', 'softmax', '0.5']
      restartPolicy: OnFailure
  backoffLimit: 0
```

`Job`을 실행하고 어떻게 돌고 있는지 확인해 봅시다.

```bash
# my-ml-job 실행
kubectl apply -f my-ml-job.yaml

# 학습 log 확인
kubectl logs -f my-ml-job-xxx
# ['train.py', '5', 'softmax', '0.5']
# Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz
# Using TensorFlow backend.
# 11460608/11490434 [============================>.] - ETA: 0s30000 train samples
# 2000 test samples
# _________________________________________________________________
# Layer (type)                 Output Shape              Param #
# =================================================================
# dense_1 (Dense)              (None, 512)               401920
# _________________________________________________________________
# ...
```

#### Clean up

```bash
kubectl delete job --all
```

---

## :trophy: Do it more

나만의 ML Job을 쿠버네티스 위에서 실행해 봅시다. 다음과 같은 테스크들을 수행해 주세요.


#### 1. 최대 timeout 설정 및 restart 휫수 설정하기

최대 timeout을 2분으로 설정하고 restart 횟수는 최대 3로 지정해주세요.

#### 2. `Job` 리소스 제약하기

`my-ml-job`이 최소 `CPU 100m / MEM 500Mi` ~ 최대 `CPU 1000m / MEM 1Gi` 의 리소스를 가질 수 있도록 `Job`을 설정해 주세요.

#### 3. 결과파일을 특정 디렉토리에 저장하기

기존의 `my-ml-job` 스크립트 맨 아래쪽에 모델을 저장하는 로직을 추가하였습니다.

```python
# train.py
import os, sys, json
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import RMSprop

...

score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

###########################
# 모델 저장 부분이 추가!
###########################
import numpy as np

weights = model.get_weights()

with open('/model_storage/mymodel.npy', 'wb') as f:
    np.save(f, weights)
```

컨테이너 내부의 `/model_storage/mymodel.npy` 모델파일이 로컬 호스트의 `/home/ubuntu` 에 저장될 수 있도록 `Job`에 볼륨을 연결해주세요.

#### 4. 결과파일을 S3에 저장하기

이번에는 `smart_open`이라는 라이브러리를 이용하여 S3에 모델을 저장해 봅시다. 기존과 거의 유사하지만 두가지만 다릅니다.

1. `from smart_open import open` 추가
2. `open` 주소 변경: `s3`로 저장해야하기 때문에 주소를 다음과 같이 수정합니다.

`s3://<BUCKET>/<USERNAME>/mymodel.npy`

- `BUCKET`: 저장할 버킷(디렉토리)을 지정합니다. (예제에서는 `mlops-2020-10`)
- `USERNAME`: 사용자별 이름을 지정합니다.

`smart_open`이라는 라이브러리를 설치합니다.

```bash
pip3 install smart_open[s3]
```

다음과 같이 수정합니다.

```python
import numpy as np
# 추가
from smart_open import open

weights = model.get_weights()
# 주소변경
with open('s3://mlops-2020-10/<USERNAME>/mymodel.npy', 'wb') as f:
    np.save(f, weights)
```

`Job`을 실행해 보고 S3에 결과값이 들어있는지 확인해봅니다.

#### 5. 여러개의 Job을 병렬로 실행해 보기 (Optional)

다음 하이퍼파라미터를 한번에 실행하는 스크립트를 작성해 봅시다.

- "5", "relu"   , "0.3"
- "5", "softmax", "0.3"
- "5", "relu"   , "0.5"
- "5", "softmax", "0.5"
- "5", "relu"   , "0.8"
- "5", "softmax", "0.8"

[HINT] 대략 다음과 같은 스크립트를 작성하면 됩니다. (파이썬 기준)

```python
JOB_TEMPLATE = """
cat << EOF | kubectl create -f -
apiVersion: batch/v1
kind: Job
metadata:
  name: ml-job-
spec:
  template:
    spec:
      containers:
      - name: ml
        image: $USERNAME/my-ml-job
        args: [%s, %s, %s]
      restartPolicy: OnFailure
  backoffLimit: 0
EOF
"""

hyperparameter_list = [
  ["5", "relu"   , "0.3"]
  ["5", "softmax", "0.3"]
  ["5", "relu"   , "0.5"]
  ["5", "softmax", "0.5"]
  ["5", "relu"   , "0.8"]
  ["5", "softmax", "0.8"]
]

for hp in hyperparameter_list:
    os.system(JOB_TEMPLATE % (hp[0], hp[1], hp[2]))
```
